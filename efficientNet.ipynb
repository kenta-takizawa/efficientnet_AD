{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600562961898",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### EfficientNetによる異常検知　kerasによる実装"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_imagenet_1000.h5\n78905344/78899776 [==============================] - 58s 1us/step\n"
    }
   ],
   "source": [
    "#import efficientNet\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model  \n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "import efficientnet as efn\n",
    "\n",
    "model = efn.EfficientNetB4(weights='imagenet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "                \n__________________________________________________________________________________________________\nconv2d_235 (Conv2D)             (None, 1, 1, 68)     111044      lambda_59[0][0]                  \n__________________________________________________________________________________________________\nswish_178 (Swish)               (None, 1, 1, 68)     0           conv2d_235[0][0]                 \n__________________________________________________________________________________________________\nconv2d_236 (Conv2D)             (None, 1, 1, 1632)   112608      swish_178[0][0]                  \n__________________________________________________________________________________________________\nactivation_61 (Activation)      (None, 1, 1, 1632)   0           conv2d_236[0][0]                 \n__________________________________________________________________________________________________\nmultiply_59 (Multiply)          (None, 12, 12, 1632) 0           activation_61[0][0]              \n                                                                 swish_177[0][0]                  \n__________________________________________________________________________________________________\nconv2d_237 (Conv2D)             (None, 12, 12, 272)  443904      multiply_59[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_178 (BatchN (None, 12, 12, 272)  1088        conv2d_237[0][0]                 \n__________________________________________________________________________________________________\ndrop_connect_39 (DropConnect)   (None, 12, 12, 272)  0           batch_normalization_178[0][0]    \n__________________________________________________________________________________________________\nadd_39 (Add)                    (None, 12, 12, 272)  0           drop_connect_39[0][0]            \n                                                                 add_38[0][0]                     \n__________________________________________________________________________________________________\nconv2d_238 (Conv2D)             (None, 12, 12, 1632) 443904      add_39[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_179 (BatchN (None, 12, 12, 1632) 6528        conv2d_238[0][0]                 \n__________________________________________________________________________________________________\nswish_179 (Swish)               (None, 12, 12, 1632) 0           batch_normalization_179[0][0]    \n__________________________________________________________________________________________________\ndepthwise_conv2d_60 (DepthwiseC (None, 12, 12, 1632) 40800       swish_179[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_180 (BatchN (None, 12, 12, 1632) 6528        depthwise_conv2d_60[0][0]        \n__________________________________________________________________________________________________\nswish_180 (Swish)               (None, 12, 12, 1632) 0           batch_normalization_180[0][0]    \n__________________________________________________________________________________________________\nlambda_60 (Lambda)              (None, 1, 1, 1632)   0           swish_180[0][0]                  \n__________________________________________________________________________________________________\nconv2d_239 (Conv2D)             (None, 1, 1, 68)     111044      lambda_60[0][0]                  \n__________________________________________________________________________________________________\nswish_181 (Swish)               (None, 1, 1, 68)     0           conv2d_239[0][0]                 \n__________________________________________________________________________________________________\nconv2d_240 (Conv2D)             (None, 1, 1, 1632)   112608      swish_181[0][0]                  \n__________________________________________________________________________________________________\nactivation_62 (Activation)      (None, 1, 1, 1632)   0           conv2d_240[0][0]                 \n__________________________________________________________________________________________________\nmultiply_60 (Multiply)          (None, 12, 12, 1632) 0           activation_62[0][0]              \n                                                                 swish_180[0][0]                  \n__________________________________________________________________________________________________\nconv2d_241 (Conv2D)             (None, 12, 12, 272)  443904      multiply_60[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_181 (BatchN (None, 12, 12, 272)  1088        conv2d_241[0][0]                 \n__________________________________________________________________________________________________\ndrop_connect_40 (DropConnect)   (None, 12, 12, 272)  0           batch_normalization_181[0][0]    \n__________________________________________________________________________________________________\nadd_40 (Add)                    (None, 12, 12, 272)  0           drop_connect_40[0][0]            \n                                                                 add_39[0][0]                     \n__________________________________________________________________________________________________\nconv2d_242 (Conv2D)             (None, 12, 12, 1632) 443904      add_40[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_182 (BatchN (None, 12, 12, 1632) 6528        conv2d_242[0][0]                 \n__________________________________________________________________________________________________\nswish_182 (Swish)               (None, 12, 12, 1632) 0           batch_normalization_182[0][0]    \n__________________________________________________________________________________________________\ndepthwise_conv2d_61 (DepthwiseC (None, 12, 12, 1632) 40800       swish_182[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_183 (BatchN (None, 12, 12, 1632) 6528        depthwise_conv2d_61[0][0]        \n__________________________________________________________________________________________________\nswish_183 (Swish)               (None, 12, 12, 1632) 0           batch_normalization_183[0][0]    \n__________________________________________________________________________________________________\nlambda_61 (Lambda)              (None, 1, 1, 1632)   0           swish_183[0][0]                  \n__________________________________________________________________________________________________\nconv2d_243 (Conv2D)             (None, 1, 1, 68)     111044      lambda_61[0][0]                  \n__________________________________________________________________________________________________\nswish_184 (Swish)               (None, 1, 1, 68)     0           conv2d_243[0][0]                 \n__________________________________________________________________________________________________\nconv2d_244 (Conv2D)             (None, 1, 1, 1632)   112608      swish_184[0][0]                  \n__________________________________________________________________________________________________\nactivation_63 (Activation)      (None, 1, 1, 1632)   0           conv2d_244[0][0]                 \n__________________________________________________________________________________________________\nmultiply_61 (Multiply)          (None, 12, 12, 1632) 0           activation_63[0][0]              \n                                                                 swish_183[0][0]                  \n__________________________________________________________________________________________________\nconv2d_245 (Conv2D)             (None, 12, 12, 272)  443904      multiply_61[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_184 (BatchN (None, 12, 12, 272)  1088        conv2d_245[0][0]                 \n__________________________________________________________________________________________________\ndrop_connect_41 (DropConnect)   (None, 12, 12, 272)  0           batch_normalization_184[0][0]    \n__________________________________________________________________________________________________\nadd_41 (Add)                    (None, 12, 12, 272)  0           drop_connect_41[0][0]            \n                                                                 add_40[0][0]                     \n__________________________________________________________________________________________________\nconv2d_246 (Conv2D)             (None, 12, 12, 1632) 443904      add_41[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_185 (BatchN (None, 12, 12, 1632) 6528        conv2d_246[0][0]                 \n__________________________________________________________________________________________________\nswish_185 (Swish)               (None, 12, 12, 1632) 0           batch_normalization_185[0][0]    \n__________________________________________________________________________________________________\ndepthwise_conv2d_62 (DepthwiseC (None, 12, 12, 1632) 40800       swish_185[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_186 (BatchN (None, 12, 12, 1632) 6528        depthwise_conv2d_62[0][0]        \n__________________________________________________________________________________________________\nswish_186 (Swish)               (None, 12, 12, 1632) 0           batch_normalization_186[0][0]    \n__________________________________________________________________________________________________\nlambda_62 (Lambda)              (None, 1, 1, 1632)   0           swish_186[0][0]                  \n__________________________________________________________________________________________________\nconv2d_247 (Conv2D)             (None, 1, 1, 68)     111044      lambda_62[0][0]                  \n__________________________________________________________________________________________________\nswish_187 (Swish)               (None, 1, 1, 68)     0           conv2d_247[0][0]                 \n__________________________________________________________________________________________________\nconv2d_248 (Conv2D)             (None, 1, 1, 1632)   112608      swish_187[0][0]                  \n__________________________________________________________________________________________________\nactivation_64 (Activation)      (None, 1, 1, 1632)   0           conv2d_248[0][0]                 \n__________________________________________________________________________________________________\nmultiply_62 (Multiply)          (None, 12, 12, 1632) 0           activation_64[0][0]              \n                                                                 swish_186[0][0]                  \n__________________________________________________________________________________________________\nconv2d_249 (Conv2D)             (None, 12, 12, 272)  443904      multiply_62[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_187 (BatchN (None, 12, 12, 272)  1088        conv2d_249[0][0]                 \n__________________________________________________________________________________________________\ndrop_connect_42 (DropConnect)   (None, 12, 12, 272)  0           batch_normalization_187[0][0]    \n__________________________________________________________________________________________________\nadd_42 (Add)                    (None, 12, 12, 272)  0           drop_connect_42[0][0]            \n                                                                 add_41[0][0]                     \n__________________________________________________________________________________________________\nconv2d_250 (Conv2D)             (None, 12, 12, 1632) 443904      add_42[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_188 (BatchN (None, 12, 12, 1632) 6528        conv2d_250[0][0]                 \n__________________________________________________________________________________________________\nswish_188 (Swish)               (None, 12, 12, 1632) 0           batch_normalization_188[0][0]    \n__________________________________________________________________________________________________\ndepthwise_conv2d_63 (DepthwiseC (None, 12, 12, 1632) 14688       swish_188[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_189 (BatchN (None, 12, 12, 1632) 6528        depthwise_conv2d_63[0][0]        \n__________________________________________________________________________________________________\nswish_189 (Swish)               (None, 12, 12, 1632) 0           batch_normalization_189[0][0]    \n__________________________________________________________________________________________________\nlambda_63 (Lambda)              (None, 1, 1, 1632)   0           swish_189[0][0]                  \n__________________________________________________________________________________________________\nconv2d_251 (Conv2D)             (None, 1, 1, 68)     111044      lambda_63[0][0]                  \n__________________________________________________________________________________________________\nswish_190 (Swish)               (None, 1, 1, 68)     0           conv2d_251[0][0]                 \n__________________________________________________________________________________________________\nconv2d_252 (Conv2D)             (None, 1, 1, 1632)   112608      swish_190[0][0]                  \n__________________________________________________________________________________________________\nactivation_65 (Activation)      (None, 1, 1, 1632)   0           conv2d_252[0][0]                 \n__________________________________________________________________________________________________\nmultiply_63 (Multiply)          (None, 12, 12, 1632) 0           activation_65[0][0]              \n                                                                 swish_189[0][0]                  \n__________________________________________________________________________________________________\nconv2d_253 (Conv2D)             (None, 12, 12, 448)  731136      multiply_63[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_190 (BatchN (None, 12, 12, 448)  1792        conv2d_253[0][0]                 \n__________________________________________________________________________________________________\nconv2d_254 (Conv2D)             (None, 12, 12, 2688) 1204224     batch_normalization_190[0][0]    \n__________________________________________________________________________________________________\nbatch_normalization_191 (BatchN (None, 12, 12, 2688) 10752       conv2d_254[0][0]                 \n__________________________________________________________________________________________________\nswish_191 (Swish)               (None, 12, 12, 2688) 0           batch_normalization_191[0][0]    \n__________________________________________________________________________________________________\ndepthwise_conv2d_64 (DepthwiseC (None, 12, 12, 2688) 24192       swish_191[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_192 (BatchN (None, 12, 12, 2688) 10752       depthwise_conv2d_64[0][0]        \n__________________________________________________________________________________________________\nswish_192 (Swish)               (None, 12, 12, 2688) 0           batch_normalization_192[0][0]    \n__________________________________________________________________________________________________\nlambda_64 (Lambda)              (None, 1, 1, 2688)   0           swish_192[0][0]                  \n__________________________________________________________________________________________________\nconv2d_255 (Conv2D)             (None, 1, 1, 112)    301168      lambda_64[0][0]                  \n__________________________________________________________________________________________________\nswish_193 (Swish)               (None, 1, 1, 112)    0           conv2d_255[0][0]                 \n__________________________________________________________________________________________________\nconv2d_256 (Conv2D)             (None, 1, 1, 2688)   303744      swish_193[0][0]                  \n__________________________________________________________________________________________________\nactivation_66 (Activation)      (None, 1, 1, 2688)   0           conv2d_256[0][0]                 \n__________________________________________________________________________________________________\nmultiply_64 (Multiply)          (None, 12, 12, 2688) 0           activation_66[0][0]              \n                                                                 swish_192[0][0]                  \n__________________________________________________________________________________________________\nconv2d_257 (Conv2D)             (None, 12, 12, 448)  1204224     multiply_64[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_193 (BatchN (None, 12, 12, 448)  1792        conv2d_257[0][0]                 \n__________________________________________________________________________________________________\ndrop_connect_43 (DropConnect)   (None, 12, 12, 448)  0           batch_normalization_193[0][0]    \n__________________________________________________________________________________________________\nadd_43 (Add)                    (None, 12, 12, 448)  0           drop_connect_43[0][0]            \n                                                                 batch_normalization_190[0][0]    \n__________________________________________________________________________________________________\nconv2d_258 (Conv2D)             (None, 12, 12, 1792) 802816      add_43[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_194 (BatchN (None, 12, 12, 1792) 7168        conv2d_258[0][0]                 \n__________________________________________________________________________________________________\nswish_194 (Swish)               (None, 12, 12, 1792) 0           batch_normalization_194[0][0]    \n__________________________________________________________________________________________________\nglobal_average_pooling2d_38 (Gl (None, 1792)         0           swish_194[0][0]                  \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 1792)         0           global_average_pooling2d_38[0][0]\n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 1000)         1793000     dropout_3[0][0]                  \n__________________________________________________________________________________________________\nactivation_67 (Activation)      (None, 1000)         0           dense_3[0][0]                    \n==================================================================================================\nTotal params: 19,466,816\nTrainable params: 19,341,616\nNon-trainable params: 125,200\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "#画像の大きさ(入力サイズ)を変えたら、どうなるの？\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4, 24, 672), dtype=float32)\nTensor(\"swish_143/swish_f32:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"depthwise_conv2d_48/depthwise:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"batch_normalization_144/cond/Merge:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"swish_144/swish_f32:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"lambda_48/Mean:0\", shape=(?, 1, 1, 672), dtype=float32)\nTensor(\"conv2d_191/BiasAdd:0\", shape=(?, 1, 1, 28), dtype=float32)\nTensor(\"swish_145/swish_f32:0\", shape=(?, 1, 1, 28), dtype=float32)\nTensor(\"conv2d_192/BiasAdd:0\", shape=(?, 1, 1, 672), dtype=float32)\nTensor(\"activation_50/Sigmoid:0\", shape=(?, 1, 1, 672), dtype=float32)\nTensor(\"multiply_48/mul:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"conv2d_193/convolution:0\", shape=(?, 24, 24, 112), dtype=float32)\nTensor(\"batch_normalization_145/cond/Merge:0\", shape=(?, 24, 24, 112), dtype=float32)\nTensor(\"drop_connect_30/cond/Merge:0\", shape=(?, 24, 24, 112), dtype=float32)\nTensor(\"add_30/add:0\", shape=(?, 24, 24, 112), dtype=float32)\nTensor(\"conv2d_194/convolution:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"batch_normalization_146/cond/Merge:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"swish_146/swish_f32:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"depthwise_conv2d_49/depthwise:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"batch_normalization_147/cond/Merge:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"swish_147/swish_f32:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"lambda_49/Mean:0\", shape=(?, 1, 1, 672), dtype=float32)\nTensor(\"conv2d_195/BiasAdd:0\", shape=(?, 1, 1, 28), dtype=float32)\nTensor(\"swish_148/swish_f32:0\", shape=(?, 1, 1, 28), dtype=float32)\nTensor(\"conv2d_196/BiasAdd:0\", shape=(?, 1, 1, 672), dtype=float32)\nTensor(\"activation_51/Sigmoid:0\", shape=(?, 1, 1, 672), dtype=float32)\nTensor(\"multiply_49/mul:0\", shape=(?, 24, 24, 672), dtype=float32)\nTensor(\"conv2d_197/convolution:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"batch_normalization_148/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"conv2d_198/convolution:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_149/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_149/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"depthwise_conv2d_50/depthwise:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_150/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_150/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"lambda_50/Mean:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"conv2d_199/BiasAdd:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"swish_151/swish_f32:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"conv2d_200/BiasAdd:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"activation_52/Sigmoid:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"multiply_50/mul:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"conv2d_201/convolution:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"batch_normalization_151/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"drop_connect_31/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"add_31/add:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"conv2d_202/convolution:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_152/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_152/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"depthwise_conv2d_51/depthwise:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_153/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_153/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"lambda_51/Mean:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"conv2d_203/BiasAdd:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"swish_154/swish_f32:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"conv2d_204/BiasAdd:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"activation_53/Sigmoid:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"multiply_51/mul:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"conv2d_205/convolution:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"batch_normalization_154/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"drop_connect_32/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"add_32/add:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"conv2d_206/convolution:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_155/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_155/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"depthwise_conv2d_52/depthwise:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_156/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_156/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"lambda_52/Mean:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"conv2d_207/BiasAdd:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"swish_157/swish_f32:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"conv2d_208/BiasAdd:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"activation_54/Sigmoid:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"multiply_52/mul:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"conv2d_209/convolution:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"batch_normalization_157/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"drop_connect_33/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"add_33/add:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"conv2d_210/convolution:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_158/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_158/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"depthwise_conv2d_53/depthwise:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_159/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_159/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"lambda_53/Mean:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"conv2d_211/BiasAdd:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"swish_160/swish_f32:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"conv2d_212/BiasAdd:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"activation_55/Sigmoid:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"multiply_53/mul:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"conv2d_213/convolution:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"batch_normalization_160/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"drop_connect_34/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"add_34/add:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"conv2d_214/convolution:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_161/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_161/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"depthwise_conv2d_54/depthwise:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_162/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_162/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"lambda_54/Mean:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"conv2d_215/BiasAdd:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"swish_163/swish_f32:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"conv2d_216/BiasAdd:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"activation_56/Sigmoid:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"multiply_54/mul:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"conv2d_217/convolution:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"batch_normalization_163/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"drop_connect_35/cond/Merge:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"add_35/add:0\", shape=(?, 24, 24, 160), dtype=float32)\nTensor(\"conv2d_218/convolution:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"batch_normalization_164/cond/Merge:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"swish_164/swish_f32:0\", shape=(?, 24, 24, 960), dtype=float32)\nTensor(\"depthwise_conv2d_55/depthwise:0\", shape=(?, 12, 12, 960), dtype=float32)\nTensor(\"batch_normalization_165/cond/Merge:0\", shape=(?, 12, 12, 960), dtype=float32)\nTensor(\"swish_165/swish_f32:0\", shape=(?, 12, 12, 960), dtype=float32)\nTensor(\"lambda_55/Mean:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"conv2d_219/BiasAdd:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"swish_166/swish_f32:0\", shape=(?, 1, 1, 40), dtype=float32)\nTensor(\"conv2d_220/BiasAdd:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"activation_57/Sigmoid:0\", shape=(?, 1, 1, 960), dtype=float32)\nTensor(\"multiply_55/mul:0\", shape=(?, 12, 12, 960), dtype=float32)\nTensor(\"conv2d_221/convolution:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"batch_normalization_166/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"conv2d_222/convolution:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_167/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_167/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"depthwise_conv2d_56/depthwise:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_168/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_168/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"lambda_56/Mean:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"conv2d_223/BiasAdd:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"swish_169/swish_f32:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"conv2d_224/BiasAdd:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"activation_58/Sigmoid:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"multiply_56/mul:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"conv2d_225/convolution:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"batch_normalization_169/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"drop_connect_36/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"add_36/add:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"conv2d_226/convolution:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_170/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_170/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"depthwise_conv2d_57/depthwise:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_171/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_171/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"lambda_57/Mean:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"conv2d_227/BiasAdd:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"swish_172/swish_f32:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"conv2d_228/BiasAdd:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"activation_59/Sigmoid:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"multiply_57/mul:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"conv2d_229/convolution:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"batch_normalization_172/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"drop_connect_37/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"add_37/add:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"conv2d_230/convolution:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_173/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_173/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"depthwise_conv2d_58/depthwise:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_174/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_174/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"lambda_58/Mean:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"conv2d_231/BiasAdd:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"swish_175/swish_f32:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"conv2d_232/BiasAdd:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"activation_60/Sigmoid:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"multiply_58/mul:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"conv2d_233/convolution:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"batch_normalization_175/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"drop_connect_38/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"add_38/add:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"conv2d_234/convolution:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_176/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_176/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"depthwise_conv2d_59/depthwise:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_177/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_177/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"lambda_59/Mean:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"conv2d_235/BiasAdd:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"swish_178/swish_f32:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"conv2d_236/BiasAdd:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"activation_61/Sigmoid:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"multiply_59/mul:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"conv2d_237/convolution:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"batch_normalization_178/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"drop_connect_39/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"add_39/add:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"conv2d_238/convolution:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_179/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_179/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"depthwise_conv2d_60/depthwise:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_180/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_180/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"lambda_60/Mean:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"conv2d_239/BiasAdd:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"swish_181/swish_f32:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"conv2d_240/BiasAdd:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"activation_62/Sigmoid:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"multiply_60/mul:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"conv2d_241/convolution:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"batch_normalization_181/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"drop_connect_40/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"add_40/add:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"conv2d_242/convolution:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_182/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_182/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"depthwise_conv2d_61/depthwise:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_183/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_183/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"lambda_61/Mean:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"conv2d_243/BiasAdd:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"swish_184/swish_f32:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"conv2d_244/BiasAdd:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"activation_63/Sigmoid:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"multiply_61/mul:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"conv2d_245/convolution:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"batch_normalization_184/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"drop_connect_41/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"add_41/add:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"conv2d_246/convolution:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_185/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_185/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"depthwise_conv2d_62/depthwise:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_186/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_186/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"lambda_62/Mean:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"conv2d_247/BiasAdd:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"swish_187/swish_f32:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"conv2d_248/BiasAdd:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"activation_64/Sigmoid:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"multiply_62/mul:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"conv2d_249/convolution:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"batch_normalization_187/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"drop_connect_42/cond/Merge:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"add_42/add:0\", shape=(?, 12, 12, 272), dtype=float32)\nTensor(\"conv2d_250/convolution:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_188/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_188/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"depthwise_conv2d_63/depthwise:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"batch_normalization_189/cond/Merge:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"swish_189/swish_f32:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"lambda_63/Mean:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"conv2d_251/BiasAdd:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"swish_190/swish_f32:0\", shape=(?, 1, 1, 68), dtype=float32)\nTensor(\"conv2d_252/BiasAdd:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"activation_65/Sigmoid:0\", shape=(?, 1, 1, 1632), dtype=float32)\nTensor(\"multiply_63/mul:0\", shape=(?, 12, 12, 1632), dtype=float32)\nTensor(\"conv2d_253/convolution:0\", shape=(?, 12, 12, 448), dtype=float32)\nTensor(\"batch_normalization_190/cond/Merge:0\", shape=(?, 12, 12, 448), dtype=float32)\nTensor(\"conv2d_254/convolution:0\", shape=(?, 12, 12, 2688), dtype=float32)\nTensor(\"batch_normalization_191/cond/Merge:0\", shape=(?, 12, 12, 2688), dtype=float32)\nTensor(\"swish_191/swish_f32:0\", shape=(?, 12, 12, 2688), dtype=float32)\nTensor(\"depthwise_conv2d_64/depthwise:0\", shape=(?, 12, 12, 2688), dtype=float32)\nTensor(\"batch_normalization_192/cond/Merge:0\", shape=(?, 12, 12, 2688), dtype=float32)\nTensor(\"swish_192/swish_f32:0\", shape=(?, 12, 12, 2688), dtype=float32)\nTensor(\"lambda_64/Mean:0\", shape=(?, 1, 1, 2688), dtype=float32)\nTensor(\"conv2d_255/BiasAdd:0\", shape=(?, 1, 1, 112), dtype=float32)\nTensor(\"swish_193/swish_f32:0\", shape=(?, 1, 1, 112), dtype=float32)\nTensor(\"conv2d_256/BiasAdd:0\", shape=(?, 1, 1, 2688), dtype=float32)\nTensor(\"activation_66/Sigmoid:0\", shape=(?, 1, 1, 2688), dtype=float32)\nTensor(\"multiply_64/mul:0\", shape=(?, 12, 12, 2688), dtype=float32)\nTensor(\"conv2d_257/convolution:0\", shape=(?, 12, 12, 448), dtype=float32)\nTensor(\"batch_normalization_193/cond/Merge:0\", shape=(?, 12, 12, 448), dtype=float32)\nTensor(\"drop_connect_43/cond/Merge:0\", shape=(?, 12, 12, 448), dtype=float32)\nTensor(\"add_43/add:0\", shape=(?, 12, 12, 448), dtype=float32)\nTensor(\"conv2d_258/convolution:0\", shape=(?, 12, 12, 1792), dtype=float32)\nTensor(\"batch_normalization_194/cond/Merge:0\", shape=(?, 12, 12, 1792), dtype=float32)\nTensor(\"swish_194/swish_f32:0\", shape=(?, 12, 12, 1792), dtype=float32)\nTensor(\"global_average_pooling2d_38/Mean:0\", shape=(?, 1792), dtype=float32)\nTensor(\"dropout_3/cond/Merge:0\", shape=(?, 1792), dtype=float32)\nTensor(\"dense_3/BiasAdd:0\", shape=(?, 1000), dtype=float32)\nTensor(\"activation_67/Softmax:0\", shape=(?, 1000), dtype=float32)\n"
    }
   ],
   "source": [
    "for a in model.layers:\n",
    "    print(a.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor 'input_3:0' shape=(?, 380, 380, 3) dtype=float32>"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "model.layers[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "44 Tensor(\"add_10/add:0\", shape=(?, 56, 56, 24), dtype=float32)\n74 Tensor(\"add_11/add:0\", shape=(?, 28, 28, 40), dtype=float32)\n104 Tensor(\"add_12/add:0\", shape=(?, 14, 14, 80), dtype=float32)\n120 Tensor(\"add_13/add:0\", shape=(?, 14, 14, 80), dtype=float32)\n150 Tensor(\"add_14/add:0\", shape=(?, 14, 14, 112), dtype=float32)\n166 Tensor(\"add_15/add:0\", shape=(?, 14, 14, 112), dtype=float32)\n196 Tensor(\"add_16/add:0\", shape=(?, 7, 7, 192), dtype=float32)\n212 Tensor(\"add_17/add:0\", shape=(?, 7, 7, 192), dtype=float32)\n228 Tensor(\"add_18/add:0\", shape=(?, 7, 7, 192), dtype=float32)\n"
    }
   ],
   "source": [
    "#keras 各層の出力を抽出する。\n",
    "add_layer_list = [[num,a]for num,a in enumerate(model.layers) if \"Add\" in str(a)]\n",
    "for num in range(len(add_layer_list)):\n",
    "    print(add_layer_list[num][0],add_layer_list[num][1].output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "swish_layer_list = [a for a in model.layers if \"(?, 112, 112, 16)\" in str(a)]\n",
    "for num in range(len(swish_layer_list)):\n",
    "    print(swish_layer_list[num].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#efficientnetの出力を表示する。\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "img = io.imread(\"./test.jpg\")\n",
    "img_resize = resize(img,(224,224,3))\n",
    "img_resize = np.expand_dims(img_resize,axis=0)\n",
    "\n",
    "img_resize2 = np.vstack((img_resize,img_resize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 32)\n(1, 32)\n(1, 32)\n"
    }
   ],
   "source": [
    "#お試し、何をやっているのかを確認する。\n",
    "from keras import backend as K \n",
    "from keras.models import Model\n",
    "inp = model.input# input placeholder\n",
    "outputs = [layer.output for layer in model.layers]# all layer outputs\n",
    "models = [Model(inputs=inp,outputs=out) for out in outputs[2:5]]\n",
    "\n",
    "new_models = []\n",
    "for num,tmp in enumerate(models):\n",
    "    input = model.input\n",
    "    x = input\n",
    "    x = tmp(x)\n",
    "    output = GlobalAveragePooling2D()(x)\n",
    "    new_models.append(Model(input,output))\n",
    "\n",
    "# Testing\n",
    "#test = np.random.random(input_shape)[np.newaxis,...]\n",
    "layer_outs = [ tmp_model.predict(img_resize) for tmp_model in new_models]\n",
    "print(layer_outs[0].shape)\n",
    "print(layer_outs[1].shape)\n",
    "print(layer_outs[2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各層からの出力をリストにまとめて出力する。\n",
    "from keras.models import Model\n",
    "\n",
    "def extract_features(model,input_data):\n",
    "    \"\"\"\n",
    "    各層の特徴量を算出する関数。\n",
    "    model:efficientnet(b0~b7)\n",
    "    input:img\n",
    "    \"\"\"\n",
    "\n",
    "    feat_list = []\n",
    "\n",
    "    select_layers = [6,14,44,74,120,166,228,-8,-5]#each layer nums\n",
    "    \n",
    "    #get each layer models\n",
    "    new_models = []\n",
    "    for num,layer_num in enumerate(select_layers):\n",
    "        input = model.input\n",
    "        x = input\n",
    "        x = model.layers[layer_num].output\n",
    "        output = GlobalAveragePooling2D()(x)\n",
    "        new_models.append(Model(input,output))\n",
    "\n",
    "    #get layer features\n",
    "    for num, tmp in enumerate(new_models):\n",
    "        feat_list.append(tmp.predict(input_data))\n",
    "\n",
    "    \n",
    "    return feat_list\n",
    "\n",
    "\n",
    "lists = extract_features(model,img_resize2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 0.21044457, -0.25377545,  1.8010106 ,  1.5387206 ,  3.7707725 ,\n         2.1740406 ,  2.300516  ,  0.525279  ,  1.6948812 ,  1.731594  ,\n         3.0381918 ,  1.9850122 ,  5.3983293 ,  1.4301822 ,  2.4775245 ,\n         2.7891462 ,  7.4035773 ,  0.7185514 ,  1.6730255 ,  0.47469485,\n         6.6796446 ,  1.9404509 ,  0.28501004,  4.4467235 ,  1.5025014 ,\n        -0.24201126,  1.6556723 ,  2.069965  ,  0.2935092 ,  0.32747853,\n         1.583767  ,  1.3538224 ],\n       [ 0.21044457, -0.25377545,  1.8010106 ,  1.5387206 ,  3.7707725 ,\n         2.1740406 ,  2.300516  ,  0.525279  ,  1.6948812 ,  1.731594  ,\n         3.0381918 ,  1.9850122 ,  5.3983293 ,  1.4301822 ,  2.4775245 ,\n         2.7891462 ,  7.4035773 ,  0.7185514 ,  1.6730255 ,  0.47469485,\n         6.6796446 ,  1.9404509 ,  0.28501004,  4.4467235 ,  1.5025014 ,\n        -0.24201126,  1.6556723 ,  2.069965  ,  0.2935092 ,  0.32747853,\n         1.583767  ,  1.3538224 ]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib.pyplot as plt\n",
    "\n",
    "#学習画像の特徴量を保存するリスト\n",
    "train_outputs = [[] for _ in range(9)]\n",
    "test_outputs = [[] for _ in range(9)]\n",
    "\n",
    "#何かしらのデータに対して適用する。\n",
    "for data in train_datas:\n",
    "    feats = extract_features(model,data)\n",
    "    \n",
    "    for f_idx, feat in enumerate(feats):\n",
    "        train_outputs[f_idx].append(feat)\n",
    "    \n",
    "    # fitting a multivariate gaussian to features extracted from every level of ImageNet pre-trained model\n",
    "    for t_idx, train_output in enumerate(train_outputs):\n",
    "        mean = np.mean(np.array(train_output),axis=0)#channel数分の平均値を算出する。\n",
    "\n",
    "        #channel数分の分散、共分散行列を求める。\n",
    "        #例えば、第１層の出力では、32次元の各軸の平均と分散を求めることになる。\n",
    "        cov = LedoitWolf().fit(np.array(train_output)).covariance_\n",
    "        train_outputs[t_idx] = [mean, cov]\n",
    "\n",
    "########################################################\n",
    "#テストデータでも同様に特徴量を計算する。\n",
    "#テストデータでは画像情報とスコアを一致させるために、正常か異常かを保存しておくこと\n",
    "gt_list = []\n",
    "\n",
    "for data in test_datas:\n",
    "    gt_list.extend(y.cpu().detach().numpy())#ラベルつけを保存しておく。\n",
    "    feats = extract_features(model,data)\n",
    "    \n",
    "    for f_idx, feat in enumerate(feats):\n",
    "        test_outputs[f_idx].append(feat)\n",
    "    \n",
    "    # fitting a multivariate gaussian to features extracted from every level of ImageNet pre-trained model\n",
    "    for t_idx, test_output in enumerate(test_outputs):\n",
    "        test_outputs[t_idx] = np.array(test_output)\n",
    "\n",
    "########################################################\n",
    "#マハラノビス距離の計算\n",
    "dist_list = []\n",
    "for t_idx, test_output in enumerate(test_outputs):\n",
    "    mean = train_outputs[t_idx][0]#学習データの平均\n",
    "    cov_inv = np.linalg.inv(train_outputs[t_idx][1])#学習データの分散\n",
    "    dist = [mahalanobis(sample, mean, cov_inv) for sample in test_output]\n",
    "    dist_list.append(np.array(dist))\n",
    "\n",
    "# Anomaly score is followed by unweighted summation of the Mahalanobis distances\n",
    "#各画像に対する異常度（距離）が出てくる。100枚の画像だったら、100個の特徴量\n",
    "scores = np.sum(np.array(dist_list), axis=0)\n",
    "\n",
    "# calculate image-level ROC AUC score\n",
    "fpr, tpr, _ = roc_curve(gt_list, scores)\n",
    "roc_auc = roc_auc_score(gt_list, scores)\n",
    "total_roc_auc.append(roc_auc)\n",
    "print('%s ROCAUC: %.3f' % (class_name, roc_auc))\n",
    "plt.plot(fpr, tpr, label='%s ROCAUC: %.3f' % (class_name, roc_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-32b548d8b93f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ImportError(\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}